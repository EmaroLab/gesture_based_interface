%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% LaTeX Template: Project Titlepage Modified (v 0.1) by rcx
%
% Original Source: http://www.howtotex.com
% Date: February 2014
% 
% This is a title page template which be used for articles & reports.
% 
% This is the modified version of the original Latex template from
% aforementioned website.
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[12pt]{article}
\usepackage[a4paper]{geometry}
\usepackage[myheadings]{fullpage}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{graphicx, wrapfig, subcaption, setspace, booktabs}
\usepackage[T1]{fontenc}
\usepackage[font=small, labelfont=bf]{caption}
\usepackage[protrusion=true, expansion=true]{microtype}
\usepackage[english]{babel}
\usepackage{sectsty}
\usepackage{url, lipsum}
\usepackage{tgbonum}
\usepackage{xcolor}
\usepackage{color}   %May be necessary if you want to color links
\usepackage{hyperref}
\hypersetup{
    pdffitwindow=false,
    colorlinks=true, %set true if you want colored links
    linktoc=all,     %set to all if you want both sections and subsections linked
    linkcolor=black,  %choose some color if you want links to stand out
}

\newcommand{\HRule}[1]{\rule{\linewidth}{#1}}
\onehalfspacing
\setcounter{tocdepth}{5}
\setcounter{secnumdepth}{5}



%-------------------------------------------------------------------------------
% HEADER & FOOTER
%-------------------------------------------------------------------------------
%\pagestyle{fancy}
%\fancyhf{}
%\setlength\headheight{15pt}
%\fancyhead[L]{Student ID: 1034511}
%\fancyhead[R]{Anglia Ruskin University}
%\fancyfoot[R]{Page \thepage\ of \pageref{LastPage}}
%-------------------------------------------------------------------------------
% TITLE PAGE
%-------------------------------------------------------------------------------
\begin{document}


{\fontfamily{cmr}\selectfont
\title{ \normalsize \textsc{}
		\\ [2.0cm]
		\HRule{0.5pt} \\
		\LARGE \textbf{\uppercase{SOFAR}
		\HRule{2pt} \\ [0.5cm]
		\normalsize \today \vspace*{5\baselineskip}}
		}

\date{}
\maketitle
\newpage

%-------------------------------------------------------------------------------
% Section title formatting
\sectionfont{\scshape}
%-------------------------------------------------------------------------------

%-------------------------------------------------------------------------------
% BODY
%-------------------------------------------------------------------------------
\tableofcontents
\newpage
\section{Overview}
The aim of the project is the development of a gesture-based interface for the Baxter robot, especially for industrial usages.\\The interface is designed to control robot in a very easy and intuitive way, by wearing a smartwatch which is in charge of recognizing some gestures. \\To improve the management of the Baxter and enforce security we introduced other devices, such as bluetooth beacons and a Kinect camera.\\When the human operator approaches to the Baxter, he can perform several operations and navigate menus through a \textbf{GUI} (Graphic User Interface) placed on the robot's head. These functionality include record, play, concatenate playbacks, ...\\The overall architecture is based on \textbf{ROS} (Robot Operating System), mainly for its IPC middleware.

\section{Introduction}

The architecture, which can be seen below, can be divided into three main blocks:
\begin{itemize}
\item Inputs
\item Logic
\item Baxter Features
\end{itemize}

TODO: <schema facile, con: HW - INPUTS - LOGIC - BAXTER FEATURES - BAXTER>

\subsection{Input Block}
The input block is in charge to communicate directly with the physical devices, collect and elaborate information and send control signal to the core, which controls the overall architecture.
\newline
There are several devices connected to the system, each one with a specific functionality:
\begin{itemize}
\item Beacons: they send signals when the operator enters within a specific zone around it.
\item Smartwatch: It sends the control signals to the core, and the information about the beacons around it.
\item Kinect: It sends an activate control if the operator is looking directly at the Baxter, and tracks it during the entire interaction. Moreover, it enforce security, blocking the robot if the operator gets too close.
\item Keyboard: another input signal, alternative to the smartwatch, mostly for testing and troubleshooting.
\end{itemize}
The whole project has been designed to be controlled by one or more devices with at least six different inputs.

\subsection{Logic}
The logic block implements the \textbf{FSM} (Finite State Machine), which is the core of the architecture: it is in charge of communicating directly with the Baxter, changing its state according to the choices made by the operator.
\newline
In order to enhance scalability, we implemented the \textit{Scan} tool in the configuration panel: the operator can set a new input control from the ROS topics, the only requirement is that the chosen topic has at least six subtopics.

\subsection{Baxter Feature}
The Baxter feature block is composed by a set of services, each one implementing a different functionality offered by the system.
The features include:
\begin{itemize}
\item Play: <spiega>
\item Record: <spiega>
\item ...
\end{itemize}

\section*{Why ROS}

The requirements for the architecture we chose to develop were:

\begin{itemize}
\item Linux-based O.S.;
\item Distributed computing;
\item Interfacing with Baxter robot;
\item Simple and modular software approach;
\item Interactive graphical user interface.
\item Scalability
\end{itemize}
The software requirements led to the choice of ROS as the IPC middleware to use. ROS is a framework that enables multiple software nodes, that could be running on different machines, to exchange data or commands on an IP network. Nodes can be implemented in C++ or Python. \\ROS is open-source and free to use under the \textit{BSD License}. The community and some hardware manufacturers provide a huge variety of packages (mainly containing ROS nodes) that are ready to be downloaded and executed without changes. \newline
In our architecture, the ROS Master must be executed on the Baxter system; on the other hand, all the other nodes can be executed in another computer (or in more than one). \\
All the Baxter control nodes are developed by \textit{Rethink Robotics}, and distributed for free.

\subsubsection{RosJava}
The choice of ROS let us include the ROSJava library to our smartwatch application, so the raw data acquired by the onboard sensors can be published directly on ROS topics, without any other intermediate.

<spiegazione dettagliata di come funziona ROS Java>

\section{Architecture}
The complete architecture can be seen below. 
<foto> 

\subsection{Behaviour of the System}
<spiegazione discorsiva>

\subsection{Project Choices}

\begin{itemize}
\item <perche abbiamo scelto questa architettura?> => scalabile, modulare, basata su molteplici controlli
\item <criticita>
\end{itemize}

Now we will enter in details of each subsystem.
\section{Inputs subsystem}
As we already explained, the Inputs subsystem is in charge to communicate directly with the peripherals, extract the raw data from them, processing them in order to extract significant information.

\subsection{Beacon}
Bluetooth beacons are hardware transmitters, a class of Bluetooth low energy devices that broadcast their identifier to nearby portable electronic devices. \\The technology enables smartphones, tablets and other devices, such as smartwatches, to perform actions when in close proximity to a beacon. \\For our project we use three \textit{Estimote Beacons} from \textit{Estimote, Inc.}. 

\subsection{Smartwatch}
The smartwatch is the most important input device of our architecture. \\The operator will control the whole system with it, through the gesture recognition. Moreover it interfaces with the beacons to determine whether it is inside a well defined area or not.\\We used the ROSJava framework in order to execute a ROS Node inside the application running in the smartwatch.\\
For our project we used a LG Watch R. \\

\subsubsection{Android Wear Application}
< parla dell'applicazione> \\
The application publish the raw data acquired from the IMU (Inertial Measurement Unit), which generates acceleration and velocity over the three cartesian axes. \\

\subsubsection{Gesture Recognition}
These data are collected by the SLOTH node, <link a github??> which recognizes if a pre-defined gesture has been performed. \\This node is based on a neural network, trained over six gestures:
\begin{itemize}
\item Wrist up
\item Wrist down
\item Wrist spike clockwise
\item Wrist spike counterclockwise
\item Wrist rotate clockwise
\item Wrist rotate counterclockwise
\end{itemize}
This node has been developed by the EmaroLab of the University of Genoa.

\subsection{Kinect}
For this project we used the Microsoft Kinect 360 (V01). \\ The device features an RGB camera, depth sensor and multi-array microphone, which can be used to both skeleton tracking and distance estimation. \\The device interfaces with the PC via USB.\\In order to let ROS node access to the raw data from the cameras, we installed all the official drivers and libraries. In the Wiki of the project we included the script to automatically download all the software needed. \\\\
The Kinect exhibits three different devices on the usb port: 
\begin{itemize}
\item Kinect camera
\item Kinect motor
\item Kinect audio
\end{itemize}
The third peripheral will not be used in this project. \\
The choice of ROS lets us include in the architecture three driver nodes which interact directly with the driver and publish onto topics the raw data.\\ These packages are:
\begin{itemize}
\item openni camera: publish data from RGB and depth optical camera
\item kinect aux: control and publish the current tilt of the camera
\item openni tracker: via RGB image and using computer vision, it recognizes and tracks the skeleton of a person
\end{itemize}
In order to track correctly the operator, he must stay still for a couple of seconds in a precise position, as we can see in the figure below \\
<foto posizione per calibrare>

<Kinect architecture>\\
<Spiegazione di tutti i nodi> \\

\begin{itemize}
\item openni camera: publish raw point cloud data onto \textit{/camera/depth/points}
\item kinect aux: publish current tilt angle onto \textit{/cur\_tilt\_angle}, and controls it according to the topic \textit{/tilt\_angle}
\item openni tracker: when a person calibrate itself, the node publish the transforms from the kinect frame to the joints (in particular head, left hand and right hand). 
\item kinect\_broadcaster
\item kinect\_to\_baxter\_broadcaster
\item tf\_shadow
\item tf\_tracker
\item kinect\_move\_server
\item kinect\_regulation\_server
\item pcl\_background\_segmentation
\item pcl\_record
\item pcl\_filter
\item position\_estimation
\item head\_tracking
\end{itemize}

\subsubsection{The frame transforms}
<albero dei frame relativi alla kinect, con breve spiegazione>

\subsection{Activation of the Baxter}
Finally, the node activation subscribe to both \textit{/odometry/baxter/head} and \textit{/beacons/activate} topics, and sends periodically a \textit{/activate} signal to the core if the operator tracked is looking toward the baxter and the beacons reveals a smartwatch in the area. \\Moreover, this node sends periodically a \textit{/secure} signal when the tracked operator is within a secure distance from the baxter. This distance is checked both with the odometry of the head and the odometry of the center of mass, estimated by the position\_estimation node, and published onto \textit{/odometry/baxter/center\_of\_mass}.

\subsection{Keyboard}
<usato solo per testing, puo essere usato diretto dalla gui per troubleshooting>

\section{Logic}
As we already explained, the Logic subsystem is the actual core of our system: it is in charge of interfacing with all the other submodules, update the GUI and sends controls to the robot. \\
In order to implement it, we used a FSM (Finite State Machine); this choice ensure scalability, so the system can be easily expanded with new states. \\
\subsection{FSM states}
<divisione in classi, tipi di stati>
\subsection{FSM architecture}
<fsm schema, con sugli archi gli eventi assocati>
\subsection{GUI}
<lucre merda>
\section{Baxter Features}
<intro>

\subsection{Simulator}
\subsection{Lista servizi}

<Spiegazione Servizi>
%
%




}
\end{document}